{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IRIS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,\n",
       " array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, 4].values\n",
    "len(y), np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, array([0, 1, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_i = LabelEncoder().fit_transform(y)\n",
    "len(y_i), np.unique(y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_i[:50], y_i[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 2),\n",
       " array([[1.4, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.3, 0.2],\n",
       "        [1.5, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.7, 0.4],\n",
       "        [1.4, 0.3],\n",
       "        [1.5, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.5, 0.1]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[:, [2,3]].values\n",
    "x.shape, x[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "留出法\n",
      "Score:  0.978\n",
      "Score:  0.978\n",
      "Score:  1.0\n",
      "Score:  0.933\n",
      "Score:  0.956\n",
      "Score:  0.933\n",
      "Score:  0.956\n",
      "Score:  0.933\n",
      "Score:  0.889\n",
      "Score:  0.933\n",
      "Acc:  0.949 +/-  0.0299\n"
     ]
    }
   ],
   "source": [
    "print(\"留出法\")\n",
    "\n",
    "n = 10\n",
    "scores = []\n",
    "for i in range(n):\n",
    "    # split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y_i, test_size=0.3, stratify=y_i, random_state=i\n",
    "    )\n",
    "    \n",
    "    # standardization\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x_train)\n",
    "    x_train_std = sc.transform(x_train)\n",
    "    x_test_std = sc.transform(x_test)\n",
    "    \n",
    "    # train\n",
    "    lr = LogisticRegression(C=100.0, random_state=1)\n",
    "    lr.fit(x_train_std, y_train)\n",
    "    \n",
    "    # score (准确率)\n",
    "    score = lr.score(x_test_std, y_test)\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(f\"Score: {score: {0}.{3}}\")\n",
    "    \n",
    "print(f\"Acc: {np.mean(scores): {0}.{3}} +/- {np.std(scores): {0}.{3}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证\n",
      "Fold: 1\n",
      "Score:  1.0\n",
      "Fold: 2\n",
      "Score:  0.933\n",
      "Fold: 3\n",
      "Score:  1.0\n",
      "Fold: 4\n",
      "Score:  1.0\n",
      "Fold: 5\n",
      "Score:  0.933\n",
      "Fold: 6\n",
      "Score:  0.933\n",
      "Fold: 7\n",
      "Score:  1.0\n",
      "Fold: 8\n",
      "Score:  1.0\n",
      "Fold: 9\n",
      "Score:  0.867\n",
      "Fold: 10\n",
      "Score:  0.933\n",
      "Acc:  0.96 +/-  0.0442\n"
     ]
    }
   ],
   "source": [
    "print(\"交叉验证\")\n",
    "\n",
    "# split\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(x, y_i)\n",
    "\n",
    "lr = LogisticRegression(C=100.0, random_state=1)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold): # k is an index\n",
    "#     print(train)\n",
    "#     print(test)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x[train])\n",
    "    x_train_std = sc.transform(x[train])\n",
    "    x_test_std = sc.transform(x[test])\n",
    "    \n",
    "    lr.fit(x_train_std, y_i[train])\n",
    "    score = lr.score(x_test_std, y_i[test])\n",
    "    scores.append(score)\n",
    "    print(f\"Fold: {k+1}\")\n",
    "    print(f\"Score: {score: {0}.{3}}\")\n",
    "    \n",
    "print(f\"Acc: {np.mean(scores): {0}.{3}} +/- {np.std(scores): {0}.{3}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping\n",
    "\n",
    "- make the size of trainning the same length as the origional size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自助法\n",
      "Score:  1.0\n",
      "Score:  0.941\n",
      "Score:  0.982\n",
      "Score:  0.957\n",
      "Score:  0.982\n",
      "Score:  1.0\n",
      "Score:  0.945\n",
      "Score:  0.933\n",
      "Score:  0.965\n",
      "Score:  0.942\n",
      "Acc:  0.965 +/-  0.0236\n"
     ]
    }
   ],
   "source": [
    "print(\"自助法\")\n",
    "\n",
    "num = len(y)\n",
    "\n",
    "def boot_strap(num:int):\n",
    "    chosen_idxes = []\n",
    "    for i in range(num):\n",
    "        rand_idx = random.randrange(0, num)\n",
    "        chosen_idxes.append(rand_idx)\n",
    "    return chosen_idxes\n",
    "\n",
    "n = 10\n",
    "scores = []\n",
    "all_index = np.arange(num)\n",
    "for i in range(n):\n",
    "    train = boot_strap(num)\n",
    "    test = list(set(all_index) - set(train))\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x[train])\n",
    "    x_train_std = sc.transform(x[train])\n",
    "    x_test_std = sc.transform(x[test])\n",
    "    \n",
    "    lr = LogisticRegression(C=100.0, random_state=i)\n",
    "    lr.fit(x_train_std, y_i[train])\n",
    "    score = lr.score(x_test_std, y_i[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Score: {score: {0}.{3}}\")\n",
    "    \n",
    "print(f\"Acc: {np.mean(scores): {0}.{3}} +/- {np.std(scores): {0}.{3}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[23, 132, 101, 74, 71, 145, 8, 124, 109, 39, 88, 86, 21, 42, 54, 68, 100, 52, 30, 86, 73, 83, 60, 131, 136, 87, 137, 141, 66, 116, 65, 9, 86, 112, 28, 43, 77, 35, 47, 1, 98, 81, 37, 31, 59, 135, 13, 109, 13, 122, 86, 24, 94, 50, 125, 38, 39, 5, 32, 60, 44, 78, 26, 120, 40, 62, 62, 70, 105, 77, 28, 128, 74, 52, 99, 70, 99, 100, 51, 89, 38, 146, 80, 19, 23, 3, 31, 58, 65, 116, 37, 112, 31, 41, 144, 95, 46, 121, 112, 77, 124, 91, 81, 0, 49, 139, 93, 52, 83, 110, 44, 131, 101, 120, 11, 15, 29, 122, 143, 110, 140, 79, 22, 79, 93, 4, 18, 103, 60, 115, 85, 39, 76, 81, 14, 35, 118, 9, 7, 31, 94, 13, 47, 18, 98, 8, 96, 89, 145, 5]\n",
      "[0 2 2 1 1 2 0 2 2 0 1 1 0 0 1 1 2 1 0 1 1 1 1 2 2 1 2 2 1 2 1 0 1 2 0 0 1\n",
      " 0 0 0 1 1 0 0 1 2 0 2 0 2 1 0 1 1 2 0 0 0 0 1 0 1 0 2 0 1 1 1 2 1 0 2 1 1\n",
      " 1 1 1 2 1 1 0 2 1 0 0 0 0 1 1 2 0 2 0 0 2 1 0 2 2 1 2 1 1 0 0 2 1 1 1 2 0\n",
      " 2 2 2 0 0 0 2 2 2 2 1 0 1 1 0 0 2 1 2 1 0 1 1 0 0 2 0 0 0 1 0 0 0 1 0 1 1\n",
      " 2 0]\n"
     ]
    }
   ],
   "source": [
    "# slice worked\n",
    "\n",
    "print(y_i)\n",
    "print(train)\n",
    "print(y_i[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
